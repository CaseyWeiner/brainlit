{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Neuron Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from AWS\n",
    "Data is downloaded via cloud-volume. Here, we select the 400th segment from the second brain segment. We scale the default chunk size of 50x50x50 by a factor of 2 in each dimension to download a 100x100x100 voxel volume."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'brainlit.utils.ngl_pipeline'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5cc7bae6721f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbrainlit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbrainlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngl_pipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNeuroglancerSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"s3://open-neurodata/brainlit/brain1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mngl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuroglancerSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'brainlit.utils.ngl_pipeline'"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
>>>>>>> 9a4a0a3e15fe7367b04a4ec3b5bfbd300b514460
   "source": [
    "import brainlit\n",
    "from brainlit.utils.session import NeuroglancerSession\n",
    "\n",
    "url = \"s3://open-neurodata/brainlit/brain1\"\n",
    "ngl = NeuroglancerSession(url, mip=6)\n",
    "img, bounds, voxel = ngl.pull_chunk(2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare plotting functions\n",
    "We add some useful plotting functions to view the downloaded volume in matplotlib (2D) and Napari (3D).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/NeuroDataDesign/mouselit/blob/master/bijan/mouse_test/final%20notebook.ipynb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import napari\n",
    "%gui qt\n",
    "\n",
    "\n",
    "def plot_2d(img, title=None, margin=0.05, dpi=80):\n",
    "    nda = sitk.GetArrayFromImage(img)\n",
    "    spacing = img.GetSpacing()\n",
    "\n",
    "    if nda.ndim == 3:\n",
    "        c = nda.shape[-1]\n",
    "\n",
    "        if c not in (3, 4):\n",
    "            nda = nda[nda.shape[0] // 2, :, :]\n",
    "\n",
    "    elif nda.ndim == 4:\n",
    "        c = nda.shape[-1]\n",
    "\n",
    "        if c not in (3, 4):\n",
    "            raise RuntimeError(\"Unable to show 3D-vector Image\")\n",
    "\n",
    "        nda = nda[nda.shape[0] // 2, :, :, :]\n",
    "\n",
    "    xsize = nda.shape[1] * 2\n",
    "    ysize = nda.shape[0] * 2\n",
    "\n",
    "    figsize = (1 + margin) * xsize / dpi, (1 + margin) * ysize / dpi\n",
    "\n",
    "    plt.figure(figsize=figsize, dpi=dpi, tight_layout=True)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    extent = (0, xsize * spacing[0], ysize * spacing[1], 0)\n",
    "\n",
    "    t = ax.imshow(nda, extent=extent, interpolation=None)\n",
    "\n",
    "    if nda.ndim == 2:\n",
    "        t.set_cmap(\"gray\")\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_3d(img, xslices=[], yslices=[], zslices=[], title=None, margin=0.05, dpi=80):\n",
    "    img_xslices = [img[s, :, :] for s in xslices]\n",
    "    img_yslices = [img[:, s, :] for s in yslices]\n",
    "    img_zslices = [img[:, :, s] for s in zslices]\n",
    "\n",
    "    maxlen = max(len(img_xslices), len(img_yslices), len(img_zslices))\n",
    "\n",
    "    img_null = sitk.Image([0, 0], img.GetPixelID(), img.GetNumberOfComponentsPerPixel())\n",
    "\n",
    "    img_slices = []\n",
    "    d = 0\n",
    "\n",
    "    if len(img_xslices):\n",
    "        img_slices += img_xslices + [img_null] * (maxlen - len(img_xslices))\n",
    "        d += 1\n",
    "\n",
    "    if len(img_yslices):\n",
    "        img_slices += img_yslices + [img_null] * (maxlen - len(img_yslices))\n",
    "        d += 1\n",
    "\n",
    "    if len(img_zslices):\n",
    "        img_slices += img_zslices + [img_null] * (maxlen - len(img_zslices))\n",
    "        d += 1\n",
    "\n",
    "    if maxlen != 0:\n",
    "        if img.GetNumberOfComponentsPerPixel() == 1:\n",
    "            img = sitk.Tile(img_slices, [maxlen, d])\n",
    "        else:\n",
    "            img_comps = []\n",
    "            for i in range(0, img.GetNumberOfComponentsPerPixel()):\n",
    "                img_slices_c = [sitk.VectorIndexSelectionCast(s, i) for s in img_slices]\n",
    "                img_comps.append(sitk.Tile(img_slices_c, [maxlen, d]))\n",
    "            img = sitk.Compose(img_comps)\n",
    "\n",
    "    plot_2d(img, title, margin, dpi)\n",
    "\n",
    "\n",
    "def napari_viewer(img, labels=None, label_name=\"Segmentation\"):\n",
    "    viewer = napari.view_image(np.squeeze(np.array(img)))\n",
    "    if labels is not None:\n",
    "        viewer.add_labels(labels, name=label_name)\n",
    "    return viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the downloaded volume. Napari will open in a new window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(img))\n",
    "print(img.shape)\n",
    "\n",
    "plot_3d(sitk.GetImageFromArray(np.squeeze(img), isVector=False), zslices=range(48,53), title = \"Downloaded Mouselight Volume\")\n",
    "napari_viewer(img)\n",
    "# viewer = napari.view_image(np.squeeze(np.array(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import astronaut\n",
    "\n",
    "# create the viewer and display the image\n",
    "viewer = napari.view_image(astronaut(), rgb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Segmentations\n",
    "Next, we will generate segmentations using the following algorithms: \\\n",
    "Gaussian Mixture Model Thresholding \\\n",
    "Otsu\\\n",
    "Connected Threshold\\\n",
    "Confidence-Connected Threshold\\\n",
    "Neighborhood-Connected Threshold\\\n",
    "Level-Set Segmentation\\\n",
    "Fast-Marching Segmentation\n",
    "\n",
    "The segmentations from the functions are output as numpy arrays, so segmentation results can easily be displayed locally and are compatible with Neuroglancer.\n",
    "\n",
    "To start, we'll import adaptive_thresh to access the segmentation algorithms and convert the cloudvolume volume of the brain to a SimpleITK image format for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.algorithms.generate_fragments import adaptive_thresh\n",
    "img_T1, img_T1_255 = adaptive_thresh.get_img_T1(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model Thresholding\n",
    "In this algorithm, a 2-component Gaussian mixture model is trained on the volume. Since neurons have higher voxel intensities in the Mouselight data than the background intensity, we threshold the entire volume by the *least* intensity in the component containing the *highest* intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.gmm_seg(img)\n",
    "print(labels.shape)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"2-Component Gaussian Mixture Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu's Method\n",
    "Otsu's method thresholds the volume into two classes (segments) by maximizing inter-class variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.otsu(img)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Otsu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Growing Methods\n",
    "Region growing methods iteratively examine pixels neighboring seed points, and determine if these neighboring pixels should be added to a region.\n",
    "Three such methods are available: \\\n",
    "In *closed-connected thresholding*, pixels in a region are connected to a seed and lie within a range of values. Here, the lower threshold is automatically calculated based on the Gaussian Mixture model thresholding above. \\\n",
    "In *neighborhood-connected thrsholding*, pixels in a region are connected to a seed and lie within a neighborhood. Again, the lower threshold is automatically calculated based on the Gaussian Mixture model thresholding above.\\\n",
    "In *confidence-connected thresholding*, pixels in a region have intensities consistent with a seed point; the pixel intensities lie within a confidence interval such that they are within some \"multiplier\" number of standard deviations from the mean of the neighborhood of the seed point. In this example, the multiplier is set to 1. If multiple iterations are used, the mean and standard deviation are calculated again at each iteration using pixels in the previous segmentation.\n",
    "\n",
    "In each of these methods, binary morphological closing is used to connect separate segments of the neuron / fill holes after the algorithm has run.\n",
    "\n",
    "We base  the algorithms on a seed set to the center of the downloaded volume, since the volume is centered on a point known to be within a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, seed = adaptive_thresh.get_seed(voxel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.connected_threshold(img, seed)\n",
    "print(labels.shape)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Closed-Connected Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.neighborhood_connected_threshold(img, seed)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Neighborhood-Connected Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.confidence_connected_threshold(img, seed, num_iter=1, multiplier=1)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Confidence-Connected Threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this thresholding doesn't appear to segment the image, we'll try again with a smaller multiplier, 80% of the value previously used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.confidence_connected_threshold(img, seed, num_iter=1, multiplier=0.8)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Confidence-Connected Threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Set Segmentation\n",
    "The level set method segments an image based on its contours. The main idea is to begin with a region based on an initial contour, and expand the region outward until edges are reached. When root mean squared change in the level set function for an iteration is below a threshold, or the maximum number of iteration have elapsed, the algorithm is said to have converged. Lower and upper thresholds may be set to the mean of the image minus or plus its standard deviation times some factor (1.5 here), if the thresholds are not set explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.level_set_seg(img, seed, factor = 1.5)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Level-Set Segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this method did effectively segment this neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast-Marching Segmentation\n",
    "The fast marching method is another form of level-set segmentation. Only a positive speed term is used to govern the differential equation in the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = adaptive_thresh.fast_marching_seg(img, seed)\n",
    "label_img = sitk.GetImageFromArray(labels, isVector=False)\n",
    "plot_3d(sitk.LabelOverlay(img_T1_255, label_img), zslices=range(48,53), title=\"Fast-Marching Segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this method did effectively segment this neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Napari to View Segmentations\n",
    "We can also view the segmentations in 3D using Napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "labels = adaptive_thresh.confidence_connected_threshold(img, seed, num_iter=1, multiplier=0.8)\n",
    "napari_viewer(img, labels, label_name=\"Confidence-Connected Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('brainlit3.7': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0bac885b99a14f584a13e00f4815af6afaf6d8259c24184e148aa35fa8ca3049"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
