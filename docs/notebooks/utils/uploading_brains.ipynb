{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alishakodibagkar/opt/anaconda3/envs/brainlit/lib/python3.8/site-packages/python_jsonschema_objects/__init__.py:50: UserWarning: Schema version http://json-schema.org/draft-04/schema not recognized. Some keywords and features may not be supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brainlit.utils import upload, session\n",
    "from pathlib import Path\n",
    "import napari\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Brain Images from data in the Octree format.\n",
    "This notebook demonstrates uploading the 2 lowest-resolution brain volumes and a `.swc` segment file.\n",
    "The upload destination could easily be set to a url of a cloud data server such as s3.\n",
    "\n",
    "## 1) Define variables.\n",
    " - `source` and `source_segments` are the root directories of the octree-formatted data and swc files.\n",
    " - `p` is the prefix string. `file://` indicates a filepath, while `s3://` or `gc://` indicate URLs.\n",
    " - `dest` and `dest_segments` are the destinations for the uploads (in this case, filepaths).\n",
    " - `num_res` denotes the number of resolutions to upload. \n",
    " \n",
    "The below paths lead to sample data in the NDD Repo. Alter the below path definitions to point to your own local file locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (Path().resolve().parents[2] / \"data\" / \"data_octree\").as_posix()\n",
    "dest = (Path().resolve().parents[2] / \"data\" / \"upload\").as_uri()\n",
    "dest_segments = (Path().resolve().parents[2] / \"data\" / \"upload_segments\").as_uri()\n",
    "dest_annotation = (Path().resolve().parents[2] / \"data\" / \"upload_annotation\").as_uri()\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Upload the image data (.tif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the upload fails with the error: `timed out on a chunk on layer index 0. moving on to the next step of pipeline`, re-run the `upload_volumes` function but with the `continue_upload` parameter, which takes `layer index` (the layer index said in the error message) and `image index` (the last succesful image that uploaded).  \n",
    "\n",
    "For example, if the output failed after image 19, then run \n",
    "`upload.upload_volumes(source, dest, num_res, continue_upload = (0, 19))`. Repeat this till all of the upload is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb89ccbabe1a420ebc4594e203c2b1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Creating precomputed volume at layer index 0'), FloatProgress(value=0.0, max=1.0), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finished layer index 0, took 6.317538022994995 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86476d5111c41628d63844d4f83e591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Creating precomputed volume at layer index 1'), FloatProgress(value=0.0, max=8.0), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finished layer index 1, took 19.865922927856445 seconds\n"
     ]
    }
   ],
   "source": [
    "upload.upload_volumes(source, dest, num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Upload the segmentation data (.swc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If uploading a `.swc` file associated with a brain volume, then use upload.py. Otherwise if uploading `swc` files with different name formats, use upload_benchmarking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79808ee0e5ec4814a55a2899c1d84a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='converting swcs to neuroglancer format...'), FloatProgress(value=0.0, max=1.0), HTM…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 1/1 [00:00<00:00, 125.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "upload.upload_segments(source, dest_segments, num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data with NeuroglancerSession and generate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "sess = session.NeuroglancerSession(url=dest, url_segments=dest_segments, mip=0)  # create session object object\n",
    "img, bounds, vertices = sess.pull_vertex_list(2, range(250, 350), expand=True)  # get image containing some data\n",
    "labels = sess.create_tubes(2, bounds, radius=1)  # generate labels via tube segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visualize the data with napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_labels(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
