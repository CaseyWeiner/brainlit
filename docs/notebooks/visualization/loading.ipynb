{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading neurons from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainlit\n",
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.Neuron_trace import NeuronTrace\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading entire neuron from AWS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`s3_trace = NeuronTrace(s3_path,seg_id,mip)` to create a NeuronTrace object with s3 file path\n",
    "`swc_trace = NeuronTrace(swc_path)` to create a NeuronTrace object with swc file path\n",
    "1. `s3_trace.get_df()` to output the s3 NeuronTrace object as a pd.DataFrame\n",
    "2. `swc_trace.get_df()` to output the swc NeuronTrace object as a pd.DataFrame\n",
    "3. `swc_trace.generate_df_subset(list_of_voxels)` creates a smaller subset of the original dataframe with coordinates in img space\n",
    "4. `swc_trace.get_df_voxel()` to output a DataFrame that converts the coordinates from spatial to voxel coordinates\n",
    "5. `swc_trace.get_graph()` to output the s3 NeuronTrace object as a netwrokx.DiGraph\n",
    "6. `swc_trace.get_paths()` to output the s3 NeuronTrace object as a list of paths\n",
    "7. `ViewerModel.add_shapes` to add the paths as a shape layer into the napari viewer\n",
    "8. `swc_trace.get_sub_neuron(bounding_box)` to output NeuronTrace object as a graph cropped by a bounding box\n",
    "9. `swc_trace.get_sub_neuron(bounding_box)` to output NeuronTrace object as paths cropped by a bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `s3_trace.get_df()`\n",
    "This function outputs the s3 NeuronTrace object as a pd.DataFrame. Each row is a vertex in the swc file with the following information: \n",
    "\n",
    "`sample number`\n",
    "\n",
    "`structure identifier`\n",
    "\n",
    "`x coordinate`\n",
    "\n",
    "`y coordinate`\n",
    "\n",
    "`z coordinate`\n",
    "\n",
    "`radius of dendrite`\n",
    "\n",
    "`sample number of parent`\n",
    "\n",
    "The coordinates are given in spatial units of micrometers ([swc specification](http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "seg_id = 2\n",
    "mip = 1\n",
    "\n",
    "s3_trace = NeuronTrace(s3_path, seg_id, mip)\n",
    "df = s3_trace.get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `swc_trace.get_df()`\n",
    "This function outputs the swc NeuronTrace object as a pd.DataFrame. Each row is a vertex in the swc file with the following information: \n",
    "\n",
    "`sample number`\n",
    "\n",
    "`structure identifier`\n",
    "\n",
    "`x coordinate`\n",
    "\n",
    "`y coordinate`\n",
    "\n",
    "`z coordinate`\n",
    "\n",
    "`radius of dendrite`\n",
    "\n",
    "`sample number of parent`\n",
    "\n",
    "The coordinates are given in spatial units of micrometers ([swc specification](http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_path = str(Path().resolve().parents[2] / \"data\" / \"data_octree\" / \"consensus-swcs\" / '2018-08-01_G-002_consensus.swc')\n",
    "\n",
    "swc_trace = NeuronTrace(path=swc_path)\n",
    "df = swc_trace.get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `swc_trace.generate_df_subset(list_of_voxels)`\n",
    "This function creates a smaller subset of the original dataframe with coordinates in img space. Each row is a vertex in the swc file with the following information: \n",
    "\n",
    "`sample number`\n",
    "\n",
    "`structure identifier`\n",
    "\n",
    "`x coordinate`\n",
    "\n",
    "`y coordinate`\n",
    "\n",
    "`z coordinate`\n",
    "\n",
    "`radius of dendrite`\n",
    "\n",
    "`sample number of parent`\n",
    "\n",
    "The coordinates are given in same spatial units as the image file when using `ngl.pull_vertex_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose vertices to use for the subneuron\n",
    "subneuron_df = df[0:3] \n",
    "vertex_list = subneuron_df['sample'].array \n",
    "\n",
    "# Define a neuroglancer session\n",
    "url = \"s3://open-neurodata/brainlit/brain1\"\n",
    "mip = 1\n",
    "ngl = NeuroglancerSession(url, mip=mip)\n",
    "\n",
    "# Get vertices\n",
    "seg_id = 2\n",
    "buffer = 10\n",
    "img, bounds, vox_in_img_list = ngl.pull_vertex_list(seg_id=seg_id, v_id_list=vertex_list, buffer = buffer, expand = True)\n",
    "\n",
    "df_subneuron = swc_trace.generate_df_subset(vox_in_img_list.tolist(),subneuron_start=0,subneuron_end=3 )\n",
    "print(df_subneuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `swc_trace.get_df_voxel()` \n",
    "\n",
    "If we want to overlay the swc file with a corresponding image, we need to make sure that they are in the same coordinate space. Because an image in an array of voxels, it makes sense to convert the vertices from spatial units into voxel units.\n",
    "\n",
    "Given the `spacing` (spatial units/voxel) and `origin` (spatial units) of the image, `swc_to_voxel` does the conversion by using the following equation:\n",
    "\n",
    "$voxel = \\frac{spatial - origin}{spacing}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = np.array([0.29875923,0.3044159,0.98840415])\n",
    "origin = np.array([70093.276,15071.596,29306.737])\n",
    "\n",
    "\n",
    "df_voxel = swc_trace.get_df_voxel(spacing=spacing, origin=origin)\n",
    "df_voxel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  `swc_trace.get_graph()`\n",
    "A neuron is a graph with no cycles (tree). While napari does not support displaying graph objects, it can display multiple paths. \n",
    "\n",
    "The DataFrame already contains all the possible edges in the neurons. Each row in the DataFrame is an edge. For example, from the above we can see that `sample 2` has `parent 1`, which represents edge `(1,2)`. `sample 1` having `parent -1` means that `sample 1` is the root of the tree.\n",
    "\n",
    " `swc_trace.get_graph()` converts the NeuronTrace object into a networkx directional graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = swc_trace.get_graph()\n",
    "print('Number of nodes:', len(G.nodes))\n",
    "print('Number of edges:', len(G.edges))\n",
    "print('\\n')\n",
    "print('Sample 1 coordinates (x,y,z)')\n",
    "print(G.nodes[1]['x'],G.nodes[1]['y'],G.nodes[1]['z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `swc_trace.get_paths()` \n",
    "This function returns the NeuronTrace object as a list of non-overlapping paths. The union of the paths forms the graph.\n",
    "\n",
    "The algorithm works by:\n",
    "\n",
    "1. Find longest path in the graph ([networkx.algorithms.dag.dag_longest_path](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.dag.dag_longest_path.html))\n",
    "2. Remove longest path from graph\n",
    "3. Repeat steps 1 and 2 until there are no more edges left in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = swc_trace.get_paths()\n",
    "print(f\"The graph was decomposed into {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. `ViewerModel.add_shapes`\n",
    "napari displays \"layers\". The most common layer is the image layer. In order to display the neuron, we use `path` from the [shapes](https://napari.org/tutorials/shapes) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_shapes(data=paths, shape_type='path', edge_color='white', name='Skeleton 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sub-neuron\n",
    "\n",
    "The image of the entire brain has dimensions of (33792, 25600, 13312) voxels. G-002 spans a sub-image of (7386, 9932, 5383) voxels. Both are too big to load in napari and overlay the neuron.\n",
    "To circumvent this, we can crop out a smaller region of the neuron, load the sub-neuron, and load the corresponding sub-image.\n",
    "\n",
    "In order to get a sub-neuron, we need to specify the `bounding_box` that will be used to crop the neuron. `bounding_box` is a length 2 tuple. The first element is one corner of the bounding box (inclusive) and the second element is the opposite corner of the bounding box (exclusive). Both corners are in voxel units.\n",
    "\n",
    "`add_swc` can do all of this automatically when given `bounding_box` by following these steps:\n",
    "\n",
    "1. `read_s3` to read the swc file into a pd.DataFrame\n",
    "2. `swc_to_voxel` to convert the coordinates from spatial to voxel coordinates\n",
    "3. `df_to_graph` to convert the DataFrame into a netwrokx.DiGraph\n",
    "**3.1 `swc.get_sub_neuron` to crop the graph by `bounding_box`**\n",
    "4. `graph_to_paths` to convert from a graph into a list of paths\n",
    "5. `ViewerModel.add_shapes` to add the paths as a shape layer into the napari viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. `swc_trace.get_sub_neuron(bounding_box)` \n",
    "### 9. `swc_trace.get_sub_neuron_paths(bounding_box)` \n",
    "\n",
    "This function crops a graph by removing edges. It removes edges that do not intersect the bounding box.\n",
    "\n",
    "Edges that intersect the bounding box will have at least one of its vertices be contained by the bounding box. The algorithm follows this principle by checking the neighborhood of vertices.\n",
    "\n",
    "For each vertex *v* in the graph:\n",
    "\n",
    "1. Find vertices belonging to local neighborhood of *v*\n",
    "2. If vertex *v* or any of its local neighborhood vertices are in the bounding box, do nothing. Otherwise, remove vertex *v* and its edges from the graph\n",
    "\n",
    "We check the neighborhood of *v* along with *v* because we want the sub-neuron to show all edges that pass through the bounding box, including edges that are only partially contained.\n",
    "\n",
    "`swc_trace.get_sub_neuron(bounding_box)` returns a sub neuron in graph format\n",
    "`swc_trace.get_sub_neuron_paths(bounding_box)` returns a sub neuron in paths format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an NGL session to get the bounding box\n",
    "url = \"s3://open-neurodata/brainlit/brain1\"\n",
    "mip = 1\n",
    "ngl = NeuroglancerSession(url, mip=mip)\n",
    "\n",
    "img, bbbox, vox = ngl.pull_chunk(2, 300, 1)\n",
    "bbox = bbbox.to_list()\n",
    "box = (bbox[:3], bbox[3:])\n",
    "print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sub = s3_trace.get_sub_neuron(box)\n",
    "paths_sub = s3_trace.get_sub_neuron_paths(box)\n",
    "print(len(G_sub))\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_shapes(data=paths_sub, shape_type='path', edge_color='blue', name='sub-neuron')\n",
    "\n",
    "# overlay corresponding image (random image but correct should be G-002_15312-4400-6448_15840-4800-6656.tif' )\n",
    "image_path = str(Path().resolve().parents[2] / \"data\" / \"data_octree\" / 'default.0.tif') \n",
    "img_comp = io.imread(image_path)\n",
    "img_comp = np.swapaxes(img_comp,0,2)\n",
    "\n",
    "viewer.add_image(img_comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
