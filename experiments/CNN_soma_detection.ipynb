{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning-Based Neuron Detection in Brain Volumes\n",
    "## *Written by Prerna Singh and John D'Uva* \n",
    "\n",
    "## Problem: In order to study morphology, connectivity, and firing characteristics of neurons, we need to know where they are located in the brain. Instead of a human manually going through terabytes of data to annotate cells, we propose a six-layer 3D convolutional neural network that can detect fluorescent neurons within given sections of a brain.\n",
    "\n",
    "## Hypothesis: This model has been previously proven to show ~95% accuracy in CLARITY-cleared brains. We believe that it may be able to generalize – with a similar degree of success – to other datasets.\n",
    "\n",
    "\n",
    "## Methods:\n",
    "    1) Isolate cell regions for 3D sliced images from Brain1\n",
    "    2) Use a brain-wide illumination correction for intensity \n",
    "    3) Extract non-cell data by assigning voxels that are just outside of ROIs to become NCR centers\n",
    "    4) Test pre-trained m1 model on ROIs and NCRs to determine generalizability \n",
    "\n",
    "### Original repo: https://github.com/prernasingh11/CLARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.swc import graph_to_paths\n",
    "import napari\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from cloudvolume import CloudVolume, view\n",
    "from tifffile import imsave\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Generate ROI subvolumes for testing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Brain1's bounding boxes and subvolume data from each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "mip = 2\n",
    "radius = 6\n",
    "v_id = 0\n",
    "\n",
    "# Create a list of imgs for each cell in 'dir' using 'pull_voxel'\n",
    "imgs = []\n",
    "ngl_sess = NeuroglancerSession(mip=mip, url=dir, url_segments=dir_segments)\n",
    "for seg_id in range(1000):\n",
    "    try:\n",
    "        # Get cell center location (0th voxel coordinates)\n",
    "        img, bbox, vox = ngl_sess.pull_voxel(seg_id, v_id, radius) \n",
    "        imgs.append(img)\n",
    "        print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with individual total intensities of {sum(sum(sum(img)))}.\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subvolume size must be 12x12x12 so remove a pixel from each dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(180):\n",
    "    imgs[i] = imgs[i][:12,:12,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually inspect data to confirm cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see ALL cells, swap the for-loop initalization with the following line:\n",
    "# for i in range(len(imgs)):\n",
    "    \n",
    "for i in range(3):\n",
    "    fig = plt.figure()\n",
    "    f, axarr = plt.subplots(1,3, figsize=(10,10) ) \n",
    "    axarr[0].set_title(\"ROI %d: Slice 3\" % i) \n",
    "    axarr[1].set_title(\"ROI %d: Slice 6\" % i) \n",
    "    axarr[2].set_title(\"ROI %d: Slice 9\" % i)\n",
    "\n",
    "    axarr[0].imshow(imgs[i][:,:,3])\n",
    "    axarr[1].imshow(imgs[i][:,:,6])\n",
    "    axarr[2].imshow(imgs[i][:,:,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closely inspect any suspicious regions in napari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "i = 90\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image( imgs[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save stack of ROI subvolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ROI_all_bias_corrected.npy', imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Generate NCR subvolumes for testing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify a voxel that is 'offset' number of voxels away from a cell center and pull a subvolume of NCR data around that voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "mip = 2\n",
    "radius = 6\n",
    "v_id = 0\n",
    "offset = radius*2\n",
    "\n",
    "# Create a list of imgs for each cell in 'dir' using 'pull_voxel'\n",
    "NCR_imgs = []\n",
    "ngl_sess = NeuroglancerSession(mip=mip, url=dir, url_segments=dir_segments)\n",
    "for seg_id in range(1000):\n",
    "    try:\n",
    "        # Get cell center location (0th voxel coordinates)\n",
    "        img, bbox, vox = ngl_sess.pull_voxel(seg_id, v_id, radius) \n",
    "        img_off = ngl_sess.pull_bounds_img(bbox + offset)\n",
    "        print(f\"\\n\\nDownloaded volume is of shape {img_off.shape}, with individual total intensities of {sum(sum(sum(img)))}.\")\n",
    "        NCR_imgs.append(img_off)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subvolume size must be 12x12x12 so remove a pixel from each dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(180):\n",
    "    NCR_imgs[i] = NCR_imgs[i][:12,:12,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually inspect data to confirm absence of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see ALL regions, swap the for-loop initalization with the following line:\n",
    "# for i in range(len(NCR_imgs)):\n",
    "    \n",
    "for i in range(3):\n",
    "    fig = plt.figure()\n",
    "    f, axarr = plt.subplots(1,3, figsize=(10,10) ) \n",
    "    axarr[0].set_title(\"NCR %d: Slice 3\" % i)\n",
    "    axarr[1].set_title(\"NCR %d: Slice 6\" % i)\n",
    "    axarr[2].set_title(\"NCR %d: Slice 9\" % i)\n",
    "    \n",
    "    axarr[0].imshow(NCR_imgs[i][:,:,3])\n",
    "    axarr[1].imshow(NCR_imgs[i][:,:,6])\n",
    "    axarr[2].imshow(NCR_imgs[i][:,:,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closely inspect any regions that look like they may contain cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "i = 104\n",
    "# path = paths[i]\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image( NCR_imgs[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any volumes that may include a cell body (values will change per dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [30 ,44-1, 67-2]:\n",
    "    NCR_imgs.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NCR_all_bias_corrected.npy', NCR_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # *Test model on current dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ROIs and NCRs into single stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_TEST = np.load('ROI_all_bias_corrected.npy')\n",
    "print(\"Total Number of Cell Regions: \", len(ROI_TEST))\n",
    "\n",
    "NCR_TEST = np.load('NCR_all_bias_corrected.npy')\n",
    "print(\"Number of Non-Cell Regions:\",len(NCR_TEST))\n",
    "\n",
    "ROI_TEST = ROI_TEST.astype(np.float32)\n",
    "print(ROI_TEST.shape)\n",
    "NCR_TEST = NCR_TEST.astype(np.float32)\n",
    "print(NCR_TEST.shape)\n",
    "\n",
    "test = np.vstack((ROI_TEST, NCR_TEST))\n",
    "\n",
    "print(\"Number of Items in Test Data: %s\" %len(test))\n",
    "test = np.expand_dims(test, axis=1)\n",
    "print('Shape of Test Data Vector:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Net Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = torch.load('model2.pt')\n",
    "# 1. Model Architecture\n",
    "# INPUT: \n",
    "# - 1 x 12 x 12 x 12 image\n",
    "# CONV1: 3d CONV\n",
    "# MAXPOOL: 3d MP\n",
    "# CONV2: 3d CONV\n",
    "# CONV3: 3d CONV\n",
    "# FC1: Fully Connected Layer\n",
    "# FC2: Fully Connected Layer\n",
    "\n",
    "class M1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M1, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(1,64, (5,5,5),padding = 2),nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.pool = nn.MaxPool3d((2, 2, 2),2) # kernel, stride\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(64, 64, (3,3,3), padding = 1), nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.conv3 = nn.Sequential(nn.Conv3d(64, 64, (3,3,3), padding = 1), nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.fc1 = nn.Sequential(nn.Linear(6*6*6*64,150),nn.Dropout(dr))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(150,1),nn.Dropout(dr))\n",
    "\n",
    "    def forward(self,x):\n",
    "#        print('Input Shape: ', x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#        print('Shape after CONV1: ', x.shape)\n",
    "        # Conv1 Activation: ReLU\n",
    "        x = self.pool(x)\n",
    "#         print('Shape after Maxpool: ', x.shape)\n",
    "        # Followed by Maxpool\n",
    "     \n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print('Shape after CONV2: ', x.shape)\n",
    "        # Conv2 Activation: ReLU\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print('Shape after CONV3: ', x.shape)\n",
    "        # Conv3 Activation: ReLU\n",
    "        \n",
    "        x = x.reshape(x.size(0),-1)\n",
    "#         print('Shape after flatten: ', x.shape)\n",
    "        # flatten vector\n",
    "              \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # FC1 Activation: ReLU\n",
    "#         print('Shape after FC1: ', x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # FC2 Activation: None\n",
    "#         print('Shape after FC2: ', x.shape)\n",
    "        m = nn.Sigmoid()\n",
    "#         print('Shape after Sigmoid Output: ', x.shape)\n",
    "\n",
    "        x = m(x)\n",
    "        # Output Activation: Sigmoid\n",
    "        return x\n",
    "\n",
    "#Hyperparamters\n",
    "num_epochs = 200\n",
    "batch_size = 5\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "dr = 0.3\n",
    "weight_decay = 1e-4\n",
    "m1 = M1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = M1()\n",
    "m1.load_state_dict(torch.load('crossvalidation4.pt', map_location = torch.device('cpu') ))\n",
    "m1 = m1.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build array of ground truth pos/neg values, preprocess data to appropriate pyTorch format, and run m1 model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabels = []\n",
    "for i in range(ROI_TEST.shape[0] ):\n",
    "    truelabels.append(1)\n",
    "for i in range(NCR_TEST.shape[0]):\n",
    "    truelabels.append(0)\n",
    "    \n",
    "labels=[]\n",
    "for i in range(len(test)):\n",
    "    w = torch.from_numpy(test[i])\n",
    "    w = w.unsqueeze(1)\n",
    "    w = w.double()\n",
    "    w = m1(w)\n",
    "    labels.append(w.detach().numpy())\n",
    "\n",
    "truelabels = np.asarray(truelabels)\n",
    "labels = np.asarray(labels)\n",
    "labels = labels.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute False/Positive Rate and True/Positive Rate using Receiver Operating Characteristics and Precision Recall pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(truelabels, labels)\n",
    "mets = sklearn.metrics.precision_recall_curve(truelabels, labels, pos_label=None, sample_weight=None)\n",
    "#np.save('positivecells.npy',positivecells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asssess accuracy with Area Under Curve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(truelabels, labels)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot False/Positive Rate vs. True/Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.title(\"AUC\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and plot F1 score using Recall vs. Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(truelabels, labels)\n",
    "auc = sklearn.metrics.auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Conclusion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our results show a consistently high degree of accuracy when utilizing the Area Under Curve score as such a measure: between 85% and 90%. This confirms our hypothesis that this model generalizes well to other datasets and implies that it has the potential to be a useful methodological addition to the Brainlit package. Some possible improvements would be: (1) increase the model's input volume size from 12x12x12 (by retraining with larger subvolumes), and (2) consider retraining with additional data from our brains. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 521,
   "position": {
    "height": "40px",
    "left": "1169px",
    "right": "20px",
    "top": "50px",
    "width": "529px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
