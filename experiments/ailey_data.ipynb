{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/thomasathey/Documents/mimlab/mouselight/env/lib/python3.8/site-packages/python_jsonschema_objects/__init__.py:50: UserWarning: Schema version http://json-schema.org/draft-04/schema not recognized. Some keywords and features may not be supported.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 7403 10240  4800     1]\n",
      "[ 7403 10240  4800     1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_04_08/gad2cre_tph2flp_con_fon_8291/561\"\n",
    "mip = 0\n",
    "\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "shape = vol_bg.shape\n",
    "print(shape)\n",
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_04_08/gad2cre_tph2flp_con_fon_8291/642\"\n",
    "mip = 0\n",
    "\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "shape = vol_fg.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_train = [[2477, 3638, 2409], [3605, 2873, 2405], [4939, 5186, 2398], [4538, 5148, 2398], [4618, 3225, 2388], [3223, 5206, 3550], [1953, 2102, 3577], [2395, 5004, 3584], [941, 3711, 708], [2030, 2164, 701], [3283, 3406, 1255], [1531, 2220, 1242], [2569, 6420, 2924], [2282, 8206, 2924], [4424, 5689, 2896], [3269, 3987, 2896], [2817, 6831, 4565], [3308, 3276, 4124], [4560, 6354, 4133], [4293, 2411, 2297]]\n",
    "centers_val = [[5701, 3357, 4137], [3610, 2346, 4137], [2564, 4086, 2829], [1282, 2182, 2829], [3960, 2836, 1546], [2347, 4866, 1545], [1680, 4284, 806], [3223, 3294, 2514], [3564, 3847, 2516], [2620, 7237, 4610]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 390it [00:06, 64.52it/s] \n",
      "Downloading: 386it [00:06, 64.16it/s] \n",
      "Downloading: 784it [00:11, 67.37it/s] \n",
      "Downloading: 790it [00:13, 59.30it/s] \n",
      "Downloading: 790it [00:11, 68.40it/s] \n",
      "Downloading: 782it [00:11, 68.58it/s] \n",
      "Downloading: 788it [00:13, 57.69it/s] \n",
      "Downloading: 786it [00:11, 70.04it/s] \n",
      "Downloading: 786it [00:11, 69.29it/s] \n",
      "Downloading: 790it [00:11, 67.85it/s] \n",
      "Downloading: 780it [00:11, 68.16it/s] \n",
      "Downloading: 786it [00:11, 67.59it/s] \n",
      "Downloading: 386it [00:05, 66.10it/s] \n",
      "Downloading: 392it [00:07, 55.09it/s]\n",
      "Downloading: 788it [00:11, 68.43it/s] \n",
      "Downloading: 790it [00:11, 68.40it/s] \n",
      "Downloading: 790it [00:11, 68.63it/s] \n",
      "Downloading: 790it [00:12, 65.80it/s] \n",
      "Downloading: 196it [00:03, 62.06it/s] \n",
      "Downloading: 186it [00:03, 60.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, center in enumerate(centers_val):\n",
    "    image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    \n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/val_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n",
    "    "
   ]
  },
  {
   "source": [
    "## View data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 392it [00:05, 74.46it/s] \n",
      "Downloading: 392it [00:04, 78.90it/s] \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Image layer 'image_bg' at 0x1657a5d90>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "center = centers_train[0]\n",
    "\n",
    "image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "image_bg = vol_bg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg)\n",
    "viewer.add_image(image_bg)"
   ]
  },
  {
   "source": [
    "## Check training results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example 0: precision: 0.005227442449430176, recall: 1.0\nExample 1: precision: 0.0, recall: nan\nExample 2: precision: 0.0, recall: nan\nExample 3: precision: 0.0, recall: nan\nExample 4: precision: nan, recall: nan\nExample 5: precision: 0.0, recall: nan\nExample 6: precision: 0.0034653465346534654, recall: 1.0\nExample 7: precision: 0.00260778859527121, recall: 1.0\nExample 8: precision: nan, recall: nan\nExample 9: precision: nan, recall: nan\nExample 10: precision: 0.0005051940260806416, recall: 1.0\nExample 11: precision: nan, recall: nan\nExample 12: precision: 0.0107095046854083, recall: 1.0\nExample 13: precision: nan, recall: nan\nExample 14: precision: 0.0, recall: nan\nExample 15: precision: 0.0, recall: nan\nExample 16: precision: nan, recall: nan\nExample 17: precision: nan, recall: nan\nExample 18: precision: nan, recall: nan\nExample 19: precision: 0.029491525423728814, recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/train_\" + str(i) + \".h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    im = f.get('image_2channel')\n",
    "    im_bg = im[0,:,:,:]\n",
    "    im_fg = im[1,:,:,:]\n",
    "\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/train_\" + str(i) + \"-image_2channel_Labels.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    gt = f.get('exported_data')\n",
    "    gt = gt[0,:,:,:]\n",
    "    pos_labels = gt == 2\n",
    "\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark_formal/train_\" + str(i) + \"-image_2channel_Probabilities.h5\"\n",
    "    f = h5py.File(fname, 'r')\n",
    "    seg = f.get('exported_data')\n",
    "    seg = seg[1,:,:,:]\n",
    "    mask = seg > 0.5\n",
    "    \n",
    "    true_pos = np.sum(np.logical_and(mask, pos_labels))\n",
    "    precision = true_pos/np.sum(mask)\n",
    "    recall = true_pos/np.sum(pos_labels)\n",
    "    print(f\"Example {i}: precision: {precision}, recall: {recall}\")\n",
    "\n",
    "    '''\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(im_bg)\n",
    "    viewer.add_image(im_fg)\n",
    "    viewer.add_labels(gt)\n",
    "    viewer.add_labels(mask)\n",
    "    '''"
   ]
  },
  {
   "source": [
    "# Old"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluate results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Read ilastik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 200, 200, 200)\n",
      "sum: 744\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark/\"\n",
    "\n",
    "part = \"4\"\n",
    "\n",
    "im_path  = base_path + part + \".tif\"\n",
    "image = io.imread(im_path)\n",
    "\n",
    "pred_path = base_path + part + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(pred_path, 'r')\n",
    "pred = f.get('exported_data')\n",
    "print(pred.shape)\n",
    "pred = pred[1,:,:,:]\n",
    "mask = pred > 0.5\n",
    "mask = removeSmallCCs(mask, 100)\n",
    "print(f\"sum: {np.sum(mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read swcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.Neuron_trace import NeuronTrace\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_path = Path(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/\" + part + \"_traces/\")\n",
    "\n",
    "swc_files = list(swc_path.glob(\"**/*.swc\"))\n",
    "\n",
    "paths_total = []\n",
    "for swc_num, swc in enumerate(swc_files):\n",
    "\n",
    "    swc_trace = NeuronTrace(path=str(swc))\n",
    "    paths = swc_trace.get_paths()\n",
    "    offset_diff, _, _, _ = swc_trace.get_df_arguments()\n",
    "\n",
    "    for path_num, p in enumerate(paths):\n",
    "        paths_total.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_mask = 0*mask\n",
    "for path in paths_total:\n",
    "    path = path.astype(int)\n",
    "    swc_mask[path[:,0], path[:,1], path[:,2]] = 1\n",
    "    \n",
    "edt = distance_transform_edt(swc_mask==0)\n",
    "swc_mask[edt < 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Labels layer 'Labels' at 0x1641747c0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.swapaxes(image,0,2))\n",
    "viewer.add_labels(np.swapaxes(mask,0,2))\n",
    "#viewer.add_labels(swc_mask)\n",
    "#viewer.add_shapes(data=paths_total, shape_type='path', edge_width=1.0, edge_color='blue', opacity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = np.sum(np.logical_and(swc_mask, np.swapaxes(mask,0,2)))/np.sum(swc_mask)\n",
    "fpr = np.sum(np.logical_and(swc_mask==0, np.swapaxes(mask==1,0,2)))/np.sum(swc_mask==0)\n",
    "print(f\"TPR: {tpr}, FPR: {fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check blocks\n",
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 4796it [01:07, 71.27it/s]  \n",
      "Downloading: 4796it [01:05, 73.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "block_num = 500\n",
    "with open(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/coords_1_unique.txt\") as fp:\n",
    "    counter = 0\n",
    "    for line in fp:\n",
    "        if counter == block_num:\n",
    "            words = line.split()\n",
    "            corner = [int(word) for word in words]\n",
    "        counter += 1\n",
    "\n",
    "dims = [200,200,600]\n",
    "image_fg = vol_fg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n",
    "image_bg = vol_bg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg[:,:,:,0])\n",
    "viewer.add_image(image_bg[:,:,:,0])\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 7194it [01:45, 67.98it/s]  \n",
      "Downloading: 7198it [01:39, 72.00it/s]  \n",
      "Downloading: 7198it [01:40, 71.44it/s]  \n",
      "Downloading: 7192it [01:33, 76.79it/s]  \n",
      "Downloading: 7192it [01:39, 72.04it/s]  \n",
      "Downloading: 7198it [01:42, 70.31it/s]  \n",
      "Downloading: 4798it [00:55, 87.11it/s]  \n",
      "Downloading: 4786it [00:54, 87.36it/s]  \n",
      "Downloading: 10790it [02:23, 75.06it/s]  \n",
      "Downloading: 10790it [02:28, 72.42it/s]  \n",
      "Downloading: 10796it [02:31, 71.36it/s]  \n",
      "Downloading: 10794it [02:23, 75.30it/s]  \n",
      "Downloading: 7190it [00:33, 214.82it/s] \n",
      "Downloading: 7188it [00:36, 198.07it/s] \n",
      "Downloading: 10796it [02:27, 73.23it/s]  \n",
      "Downloading: 10798it [02:34, 70.03it/s]  \n",
      "Downloading: 10796it [02:33, 70.40it/s]  \n",
      "Downloading: 10798it [02:31, 71.18it/s]  \n",
      "Downloading: 4796it [01:07, 71.18it/s]  \n",
      "Downloading: 4792it [01:07, 70.76it/s]  \n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "\n",
    "s = sample(list(np.arange(0, 659)), 10)\n",
    "dims = [200,200,600]\n",
    "\n",
    "for block_num in s:\n",
    "    with open(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/coords_1_unique.txt\") as fp:\n",
    "        counter = 0\n",
    "        for line in fp:\n",
    "            if counter == block_num:\n",
    "                words = line.split()\n",
    "                corner = [int(word) for word in words]\n",
    "            counter += 1\n",
    "    upper_bd = [np.amin([corner[i]+dims[i], vol_fg.shape[i]]) for i in range(3)]\n",
    "    image_fg = vol_fg[corner[0]:upper_bd[0], corner[1]:upper_bd[1], corner[2]:upper_bd[2]]\n",
    "    image_bg = vol_bg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading output\n",
      "Reading input\n"
     ]
    }
   ],
   "source": [
    "#0,1,2,3,5 artifact (2)\n",
    "#4,7,8,9 - positive, 6?\n",
    "blocks = [62, 115, 155, 277, 304, 358, 424, 508, 622, 636]\n",
    "block_num = blocks[5]\n",
    "print(\"Reading output\")\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, \"r\")\n",
    "ks = list(f.keys())\n",
    "pred = f[ks[0]]\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "labels = measure.label(mask)\n",
    "props = measure.regionprops(labels)\n",
    "for prop in props:\n",
    "    if prop.area < 100:\n",
    "        labels[labels == prop.label] = 0\n",
    "\n",
    "\n",
    "print(\"Reading input\")\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \".h5\"\n",
    "f = h5py.File(fname, \"r\")\n",
    "ks = list(f.keys())\n",
    "im = f[ks[0]]\n",
    "im_bg = im[0,:,:,:,0]\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_bg)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(labels)\n",
    "napari.run()"
   ]
  },
  {
   "source": [
    "# Make annotation layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Making new annotation layer\n",
    "-output data and x,y,z bounds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Vec(7403,10240,4800, dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "vol_bg.volume_size"
   ]
  },
  {
   "source": [
    "cannot write to https link, can write to s3 link"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://smartspim-precomputed-volumes/2021_04_08/gad2cre_tph2flp_con_fon_8291/axon_mask\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_bg.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_bg.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 128, 128, 2 ], # units are voxels\n",
    "    volume_size     = vol_bg.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(dir, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 50it [00:00, 55.15it/s]\n",
      "Downloading: 76it [00:00, 79.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_fg = vol_fg[2432:2560, 3584:3712, 2400:2440]\n",
    "image_bg = vol_bg[2432:2560, 3584:3712, 2400:2440]\n",
    "image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example.h5\"\n",
    "with h5py.File(fname, \"w\") as f:\n",
    "    dset = f.create_dataset(\"image_2channel\", data=image_2channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "example = \"off_2\"\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "im = f.get('image_2channel')\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "pred = f.get('exported_data')\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "try:\n",
    "    mask = removeSmallCCs(mask, 100)\n",
    "except ValueError:\n",
    "    mask = 0*im_fg\n",
    "\n",
    "print(im_fg.shape == mask.shape)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(mask)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Uploading:   0%|          | 0/20 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "vol[2432:2560, 3584:3712, 2400:2440] = mask.astype('uint64')"
   ]
  },
  {
   "source": [
    "https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=E-917tNc_GylnQ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Brainlit example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain2/axons\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_brainlit.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_brainlit.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 68, 52, 80 ], # units are voxels\n",
    "    volume_size     = vol_brainlit.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(dir, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((68,52,80), dtype='uint64')\n",
    "a[30:35,:,:] = 1\n",
    "vol[:68,:52,:80] = a"
   ]
  },
  {
   "source": [
    "# Second sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_06_02_Sert_Cre/Ch_647\"\n",
    "\n",
    "vol_fg = CloudVolume(dir)"
   ]
  },
  {
   "source": [
    "## Download and save samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 2388it [00:36, 65.59it/s] \n",
      "Downloading: 2390it [00:27, 86.18it/s]  \n",
      "Downloading: 3594it [00:50, 71.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "pos_centers = [[3071, 765, 2342], [5065, 3455, 2342], [3262, 7854, 2342]] #tectum, cortex, olfactory bulb\n",
    "neg_centers = [[3557, 4797, 2342], [1564, 1997, 2342], [1606, 5204, 2342]] #?, edge of brain/tectum, white matter\n",
    "radius = 100\n",
    "\n",
    "for i, center in enumerate(pos_centers):\n",
    "    image_fg = vol_fg[center[0]-radius:center[0]+radius, center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = 0*image_fg\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/on_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n",
    "\n",
    "\n",
    "for i, center in enumerate(neg_centers):\n",
    "    image_fg = vol_fg[center[0]-radius:center[0]+radius, center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = 0*image_fg\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/off_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)"
   ]
  },
  {
   "source": [
    "## Read ilastik results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "example = \"off_2\"\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/\" + example + \".h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "im = f.get('image_2channel')\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/\" + example + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "pred = f.get('exported_data')\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "\n",
    "try:\n",
    "    mask = removeSmallCCs(mask, 100)\n",
    "except ValueError:\n",
    "    mask = 0*im_fg\n",
    "\n",
    "print(im_fg.shape == mask.shape)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(mask)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env_37_demo",
   "display_name": "env_37_demo",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}