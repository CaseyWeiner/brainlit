{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 7403 10240  4800     1]\n",
      "[ 7403 10240  4800     1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_04_08/gad2cre_tph2flp_con_fon_8291/561\"\n",
    "mip = 0\n",
    "\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "shape = vol_bg.shape\n",
    "print(shape)\n",
    "\n",
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_04_08/gad2cre_tph2flp_con_fon_8291/642\"\n",
    "mip = 0\n",
    "\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=mip, fill_missing=True)\n",
    "shape = vol_fg.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 3590it [00:17, 208.22it/s]\n",
      "<ipython-input-61-84ab54b32859>:15: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/on_4.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 3598it [00:17, 203.36it/s]\n",
      "<ipython-input-61-84ab54b32859>:20: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/on_4_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n"
     ]
    }
   ],
   "source": [
    "centers = [[2477, 3638, 2409], [3605, 2873, 2405], [4939, 5186, 2398], [4538, 5148, 2398], [4618, 3225, 2388], [3223, 5206, 3550], [1953, 2102, 3577], [2395, 5004, 3584], [941, 3711, 708], [2030, 2164]]\n",
    "\n",
    "\n",
    "for i in [4]:\n",
    "    center = centers[i]\n",
    "    image_fg = vol_fg[center[0]-49:center[0]+50,center[1]-49:center[1]+50, center[2]-49:center[2]+50]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/on_\" + str(i) + \".tif\"\n",
    "    io.imsave(fname, image_fg)\n",
    "\n",
    "    image_bg = vol_bg[center[0]-radius:center[0]+radius,center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/on_\" + str(i) + \"_background.tif\"\n",
    "    io.imsave(fname, image_bg)\n",
    "    '''\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(image_fg)\n",
    "    viewer.add_image(image_bg)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-55-88f0bba56212>:2: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/on_4_background.tif is a low contrast image\n  io.imsave(fname, image_bg)\n"
     ]
    }
   ],
   "source": [
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/on_\" + str(i) + \"_background.tif\"\n",
    "io.imsave(fname, image_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 3598it [00:19, 181.48it/s]\n",
      "Downloading: 3586it [00:16, 214.01it/s]\n"
     ]
    }
   ],
   "source": [
    "centers = [[3104, 3700, 2373], [2365, 3753, 2373], [3615, 3671, 2373], [2556, 5182, 2373], [2231, 4961, 2719], [2570, 6194, 2493], [2647, 4247, 1911], [3623, 3732, 2423], [2681, 3426, 2436], [3603, 3669, 2490]]\n",
    "#0, 1, 4, 5, 8 - thin more obvious axons\n",
    "#2, 3, 6,7,9 - thick and faint\n",
    "\n",
    "i=4\n",
    "#one axon? - 0,4,6,7,8,9\n",
    "#def not - 1,2,3,5\n",
    "center = centers[i]\n",
    "radius = 100\n",
    "image_fg = vol_fg[center[0]-radius:center[0]+radius,center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "image_bg = vol_bg[center[0]-radius:center[0]+radius,center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<HDF5 dataset \"image_2channel\": shape (2, 200, 200, 200), type \"<u2\">"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "hf = h5py.File( \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/on_\" + str(i) + \".h5\", 'w')\n",
    "hf.create_dataset('image_2channel', data=image_2channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 200, 200, 200)"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "hf = h5py.File(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/on_\" + str(i) + \".h5\", 'r')\n",
    "pred = hf.get('image_2channel')\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab random subvolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 3598it [00:40, 88.58it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/0.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 3588it [00:40, 89.30it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/0_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 1596it [00:19, 80.49it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/1.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 1592it [00:20, 79.16it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/1_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 3594it [00:44, 80.96it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/2.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 3594it [00:38, 93.62it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/2_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 3596it [00:40, 89.80it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/3.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 3598it [00:39, 91.13it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/3_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2398it [00:27, 87.73it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/4.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2394it [00:26, 88.76it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/4_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2396it [00:26, 89.82it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/5.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2392it [00:26, 90.51it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/5_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2392it [00:28, 83.14it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/6.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2396it [00:26, 88.86it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/6_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2394it [00:26, 90.95it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/7.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2386it [00:27, 85.57it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/7_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2392it [00:32, 74.10it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/8.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2394it [00:26, 89.55it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/8_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n",
      "Downloading: 2394it [00:26, 89.65it/s]\n",
      "<ipython-input-5-936f82594fb0>:11: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/9.tif is a low contrast image\n",
      "  io.imsave(fname, image_fg)\n",
      "Downloading: 2396it [00:26, 90.95it/s]\n",
      "<ipython-input-5-936f82594fb0>:17: UserWarning: /Users/thomasathey/Documents/mimlab/mouselight/ailey/9_background.tif is a low contrast image\n",
      "  io.imsave(fname, image_bg)\n"
     ]
    }
   ],
   "source": [
    "centers = [[2636, 2786, 3978], [5391, 1147, 3026],[5544, 1113, 2885],[5542, 482, 3570],[3040, 2916, 2633],[4229, 7898, 3646],[5240, 3523, 4025],[1285, 3131, 2060],[1154, 4651, 880],[4369, 6951, 2393]]\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    center = centers[i]\n",
    "    radius = 100\n",
    "    image_fg = vol_fg[center[0]-radius:center[0]+radius,center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/\" + str(i) + \".tif\"\n",
    "    io.imsave(fname, image_fg)\n",
    "\n",
    "    image_bg = vol_bg[center[0]-radius:center[0]+radius,center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/\" + str(i) + \"_background.tif\"\n",
    "    io.imsave(fname, image_bg)\n",
    "    '''\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(image_fg)\n",
    "    viewer.add_image(image_bg)\n",
    "    '''"
   ]
  },
  {
   "source": [
    "# Evaluate results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Read ilastik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 200, 200, 200)\n",
      "sum: 744\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/benchmark/\"\n",
    "\n",
    "part = \"4\"\n",
    "\n",
    "im_path  = base_path + part + \".tif\"\n",
    "image = io.imread(im_path)\n",
    "\n",
    "pred_path = base_path + part + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(pred_path, 'r')\n",
    "pred = f.get('exported_data')\n",
    "print(pred.shape)\n",
    "pred = pred[1,:,:,:]\n",
    "mask = pred > 0.5\n",
    "mask = removeSmallCCs(mask, 100)\n",
    "print(f\"sum: {np.sum(mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read swcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.Neuron_trace import NeuronTrace\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_path = Path(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/\" + part + \"_traces/\")\n",
    "\n",
    "swc_files = list(swc_path.glob(\"**/*.swc\"))\n",
    "\n",
    "paths_total = []\n",
    "for swc_num, swc in enumerate(swc_files):\n",
    "\n",
    "    swc_trace = NeuronTrace(path=str(swc))\n",
    "    paths = swc_trace.get_paths()\n",
    "    offset_diff, _, _, _ = swc_trace.get_df_arguments()\n",
    "\n",
    "    for path_num, p in enumerate(paths):\n",
    "        paths_total.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_mask = 0*mask\n",
    "for path in paths_total:\n",
    "    path = path.astype(int)\n",
    "    swc_mask[path[:,0], path[:,1], path[:,2]] = 1\n",
    "    \n",
    "edt = distance_transform_edt(swc_mask==0)\n",
    "swc_mask[edt < 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Labels layer 'Labels' at 0x1641747c0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.swapaxes(image,0,2))\n",
    "viewer.add_labels(np.swapaxes(mask,0,2))\n",
    "#viewer.add_labels(swc_mask)\n",
    "#viewer.add_shapes(data=paths_total, shape_type='path', edge_width=1.0, edge_color='blue', opacity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = np.sum(np.logical_and(swc_mask, np.swapaxes(mask,0,2)))/np.sum(swc_mask)\n",
    "fpr = np.sum(np.logical_and(swc_mask==0, np.swapaxes(mask==1,0,2)))/np.sum(swc_mask==0)\n",
    "print(f\"TPR: {tpr}, FPR: {fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check blocks\n",
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 4796it [01:07, 71.27it/s]  \n",
      "Downloading: 4796it [01:05, 73.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "block_num = 500\n",
    "with open(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/coords_1_unique.txt\") as fp:\n",
    "    counter = 0\n",
    "    for line in fp:\n",
    "        if counter == block_num:\n",
    "            words = line.split()\n",
    "            corner = [int(word) for word in words]\n",
    "        counter += 1\n",
    "\n",
    "dims = [200,200,600]\n",
    "image_fg = vol_fg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n",
    "image_bg = vol_bg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(image_fg[:,:,:,0])\n",
    "viewer.add_image(image_bg[:,:,:,0])\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 7194it [01:45, 67.98it/s]  \n",
      "Downloading: 7198it [01:39, 72.00it/s]  \n",
      "Downloading: 7198it [01:40, 71.44it/s]  \n",
      "Downloading: 7192it [01:33, 76.79it/s]  \n",
      "Downloading: 7192it [01:39, 72.04it/s]  \n",
      "Downloading: 7198it [01:42, 70.31it/s]  \n",
      "Downloading: 4798it [00:55, 87.11it/s]  \n",
      "Downloading: 4786it [00:54, 87.36it/s]  \n",
      "Downloading: 10790it [02:23, 75.06it/s]  \n",
      "Downloading: 10790it [02:28, 72.42it/s]  \n",
      "Downloading: 10796it [02:31, 71.36it/s]  \n",
      "Downloading: 10794it [02:23, 75.30it/s]  \n",
      "Downloading: 7190it [00:33, 214.82it/s] \n",
      "Downloading: 7188it [00:36, 198.07it/s] \n",
      "Downloading: 10796it [02:27, 73.23it/s]  \n",
      "Downloading: 10798it [02:34, 70.03it/s]  \n",
      "Downloading: 10796it [02:33, 70.40it/s]  \n",
      "Downloading: 10798it [02:31, 71.18it/s]  \n",
      "Downloading: 4796it [01:07, 71.18it/s]  \n",
      "Downloading: 4792it [01:07, 70.76it/s]  \n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "\n",
    "s = sample(list(np.arange(0, 659)), 10)\n",
    "dims = [200,200,600]\n",
    "\n",
    "for block_num in s:\n",
    "    with open(\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/coords_1_unique.txt\") as fp:\n",
    "        counter = 0\n",
    "        for line in fp:\n",
    "            if counter == block_num:\n",
    "                words = line.split()\n",
    "                corner = [int(word) for word in words]\n",
    "            counter += 1\n",
    "    upper_bd = [np.amin([corner[i]+dims[i], vol_fg.shape[i]]) for i in range(3)]\n",
    "    image_fg = vol_fg[corner[0]:upper_bd[0], corner[1]:upper_bd[1], corner[2]:upper_bd[2]]\n",
    "    image_bg = vol_bg[corner[0]:corner[0]+dims[0], corner[1]:corner[1]+dims[1], corner[2]:corner[2]+dims[2]]\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading output\n",
      "Reading input\n"
     ]
    }
   ],
   "source": [
    "#0,1,2,3,5 artifact (2)\n",
    "#4,7,8,9 - positive, 6?\n",
    "blocks = [62, 115, 155, 277, 304, 358, 424, 508, 622, 636]\n",
    "block_num = blocks[5]\n",
    "print(\"Reading output\")\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, \"r\")\n",
    "ks = list(f.keys())\n",
    "pred = f[ks[0]]\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "labels = measure.label(mask)\n",
    "props = measure.regionprops(labels)\n",
    "for prop in props:\n",
    "    if prop.area < 100:\n",
    "        labels[labels == prop.label] = 0\n",
    "\n",
    "\n",
    "print(\"Reading input\")\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/wholebrain_results/images/on_\" + str(block_num) + \".h5\"\n",
    "f = h5py.File(fname, \"r\")\n",
    "ks = list(f.keys())\n",
    "im = f[ks[0]]\n",
    "im_bg = im[0,:,:,:,0]\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_bg)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(labels)\n",
    "napari.run()"
   ]
  },
  {
   "source": [
    "# Make annotation layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Making new annotation layer\n",
    "-output data and x,y,z bounds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Vec(7403,10240,4800, dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "vol_bg.volume_size"
   ]
  },
  {
   "source": [
    "cannot write to https link, can write to s3 link"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://smartspim-precomputed-volumes/2021_04_08/gad2cre_tph2flp_con_fon_8291/axon_mask\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_bg.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_bg.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 128, 128, 2 ], # units are voxels\n",
    "    volume_size     = vol_bg.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(dir, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 50it [00:00, 55.15it/s]\n",
      "Downloading: 76it [00:00, 79.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_fg = vol_fg[2432:2560, 3584:3712, 2400:2440]\n",
    "image_bg = vol_bg[2432:2560, 3584:3712, 2400:2440]\n",
    "image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example.h5\"\n",
    "with h5py.File(fname, \"w\") as f:\n",
    "    dset = f.create_dataset(\"image_2channel\", data=image_2channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "example = \"off_2\"\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "im = f.get('image_2channel')\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/example_annotation/example_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "pred = f.get('exported_data')\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "try:\n",
    "    mask = removeSmallCCs(mask, 100)\n",
    "except ValueError:\n",
    "    mask = 0*im_fg\n",
    "\n",
    "print(im_fg.shape == mask.shape)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(mask)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading:   0%|          | 0/20 [00:00<?, ?it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "Uploading: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Uploading:   0%|          | 0/20 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "vol[2432:2560, 3584:3712, 2400:2440] = mask.astype('uint64')"
   ]
  },
  {
   "source": [
    "https://viz.neurodata.io/?json_url=https://json.neurodata.io/v1?NGStateID=E-917tNc_GylnQ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Brainlit example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain2/axons\"\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    encoding        = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution      = vol_brainlit.resolution, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = vol_brainlit.voxel_offset, # x,y,z offset in voxels from the origin\n",
    "    # mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 68, 52, 80 ], # units are voxels\n",
    "    volume_size     = vol_brainlit.volume_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(dir, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Uploading: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n",
      "Uploading:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((68,52,80), dtype='uint64')\n",
    "a[30:35,:,:] = 1\n",
    "vol[:68,:52,:80] = a"
   ]
  },
  {
   "source": [
    "# Second sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"precomputed://https://dlab-colm.neurodata.io/2021_06_02_Sert_Cre/Ch_647\"\n",
    "\n",
    "vol_fg = CloudVolume(dir)"
   ]
  },
  {
   "source": [
    "## Download and save samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 2388it [00:36, 65.59it/s] \n",
      "Downloading: 2390it [00:27, 86.18it/s]  \n",
      "Downloading: 3594it [00:50, 71.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "pos_centers = [[3071, 765, 2342], [5065, 3455, 2342], [3262, 7854, 2342]] #tectum, cortex, olfactory bulb\n",
    "neg_centers = [[3557, 4797, 2342], [1564, 1997, 2342], [1606, 5204, 2342]] #?, edge of brain/tectum, white matter\n",
    "radius = 100\n",
    "\n",
    "for i, center in enumerate(pos_centers):\n",
    "    image_fg = vol_fg[center[0]-radius:center[0]+radius, center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = 0*image_fg\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/on_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)\n",
    "\n",
    "\n",
    "for i, center in enumerate(neg_centers):\n",
    "    image_fg = vol_fg[center[0]-radius:center[0]+radius, center[1]-radius:center[1]+radius, center[2]-radius:center[2]+radius]\n",
    "    image_bg = 0*image_fg\n",
    "    image_2channel = np.stack([image_bg, image_fg], axis=0)\n",
    "    fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/off_\" + str(i) + \".h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_2channel\", data=image_2channel)"
   ]
  },
  {
   "source": [
    "## Read ilastik results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "example = \"off_2\"\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/\" + example + \".h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "im = f.get('image_2channel')\n",
    "im_fg = im[1,:,:,:,0]\n",
    "\n",
    "fname = \"/Users/thomasathey/Documents/mimlab/mouselight/ailey/brain2_data/images/\" + example + \"_Probabilities_3d_2channel.h5\"\n",
    "f = h5py.File(fname, 'r')\n",
    "pred = f.get('exported_data')\n",
    "pred = pred[1,:,:,:,0]\n",
    "mask = pred > 0.5\n",
    "\n",
    "try:\n",
    "    mask = removeSmallCCs(mask, 100)\n",
    "except ValueError:\n",
    "    mask = 0*im_fg\n",
    "\n",
    "print(im_fg.shape == mask.shape)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(im_fg)\n",
    "viewer.add_labels(mask)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env_37_demo",
   "display_name": "env_37_demo",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}