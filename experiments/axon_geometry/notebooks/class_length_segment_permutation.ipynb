{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define brain, find trace data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Directory where swcs reside: /Users/thomasathey/Documents/mimlab/mouselight/brainlit_parent/brainlit/experiments/axon_geometry/data/brain1/segments_swc\n"
     ]
    }
   ],
   "source": [
    "#specify brain1 or brain2 below\n",
    "brain = \"brain1\"\n",
    "\n",
    "root_dir = Path(os.path.abspath('')).parents[1]\n",
    "experiment_dir = os.path.join(root_dir, \"axon_geometry\")\n",
    "data_dir = os.path.join(experiment_dir, \"data\", brain)\n",
    "segments_swc_dir = os.path.join(data_dir, \"segments_swc\")\n",
    "trace_data_dir = os.path.join(data_dir, \"trace_data\")\n",
    "trace_data_dir = os.path.join(trace_data_dir, \"14\")\n",
    "print(f\"Directory where swcs reside: {segments_swc_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read trace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = 300\n",
    "\n",
    "\n",
    "def classify_height(row):\n",
    "    height = row[\"height\"]\n",
    "    if height <= 2:\n",
    "        return height\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def numerical_class(row):\n",
    "    _class = row[\"class\"]\n",
    "    if _class == \"axon\":\n",
    "        return 0\n",
    "    if _class == \"collateral\":\n",
    "        return 1\n",
    "    if _class == \"terminal\":\n",
    "        return 2\n",
    "\n",
    "df_path = os.path.join(trace_data_dir, \"df.csv\")\n",
    "if os.path.exists(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"seg_id\", \"class\", \"height\", \"log_seg_length\", \"measure\", \"value\", \"log_value\"])\n",
    "    for i in np.arange(0, max_id):\n",
    "        i = int(i)\n",
    "        trace_data_path = os.path.join(trace_data_dir, \"{}.npy\".format(i))\n",
    "        if os.path.exists(trace_data_path) is True:\n",
    "            trace_data = np.load(trace_data_path, allow_pickle=True)\n",
    "            print(\"Loaded segment {}\".format(i))\n",
    "\n",
    "            for node in trace_data:\n",
    "                seg_length = node[\"seg_length\"]\n",
    "                height = node[\"height\"]\n",
    "                _class = node[\"class\"]\n",
    "                mean_curvature = node[\"mean_curvature\"]\n",
    "                mean_torsion = node[\"mean_torsion\"]\n",
    "                \n",
    "                log_seg_length = np.log10(seg_length)\n",
    "\n",
    "                log_mean_curvature = np.log10(mean_curvature)\n",
    "                df = df.append({\"seg_id\": i, \"height\": height, \"class\": _class, \"log_seg_length\": log_seg_length, \"measure\": \"curvature\", \"value\": mean_curvature, \"log_value\": log_mean_curvature}, ignore_index=True)\n",
    "\n",
    "                log_mean_torsion = np.log10(mean_torsion)\n",
    "                df = df.append({\"seg_id\": i, \"height\": height, \"class\": _class, \"log_seg_length\": log_seg_length, \"measure\": \"torsion\", \"value\": mean_torsion, \"log_value\": log_mean_torsion}, ignore_index=True)\n",
    "    df.to_csv(df_path)\n",
    "df[\"class\"] = df.apply(numerical_class, axis=1)\n",
    "df[\"height_class\"] = df.apply(classify_height, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Permutation Test\n",
    "Using Freedman and Lane 1983 method as described in Winkler et. al. 2014 Permutation inference for the general linear model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 381.57it/s]\n",
      "collateral > primary in curvature\n",
      "p-val was: 9.999000099990002e-05\n",
      "100%|██████████| 10000/10000 [00:49<00:00, 202.80it/s]\n",
      "terminal > primary in curvature\n",
      "p-val was: 9.999000099990002e-05\n",
      "100%|██████████| 10000/10000 [01:06<00:00, 151.19it/s]\n",
      "terminal < collateral in curvature\n",
      "p-val was: 9.999000099990002e-05\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 381.63it/s]\n",
      "collateral > primary in torsion\n",
      "p-val was: 9.999000099990002e-05\n",
      "100%|██████████| 10000/10000 [00:52<00:00, 192.16it/s]\n",
      "terminal ~= primary in torsion\n",
      "upper p-val was: 0.0570942905709429, lower was 0.943005699430057\n",
      "100%|██████████| 10000/10000 [01:05<00:00, 151.65it/s]terminal < collateral in torsion\n",
      "p-val was: 9.999000099990002e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_perms = 10000\n",
    "\n",
    "measures = [\"curvature\", \"torsion\"]\n",
    "\n",
    "classes = {0: \"primary\", 1: \"collateral\", 2: \"terminal\"}\n",
    "n = len(classes)\n",
    "matrix_pairs = np.triu(np.ones((n, n)), k=1)\n",
    "(coord_pairs_x, coord_pairs_y) = np.where(matrix_pairs == 1)\n",
    "\n",
    "for measure in measures:\n",
    "    for class_1, class_2 in zip(coord_pairs_x, coord_pairs_y):\n",
    "        Y = []\n",
    "        segment_numbers = []\n",
    "        X_class = []\n",
    "        neuron_id = 0\n",
    "        #collect data from all neurons\n",
    "        for i in np.arange(0, max_id):\n",
    "            sample_query = df.loc[(df['seg_id'] == i) & ((df['class'] == class_1) | (df['class'] == class_2)) & (df['measure'] == measure)]\n",
    "            num_segments = len(sample_query.index)\n",
    "            if num_segments > 0:\n",
    "                Y.append(sample_query[\"value\"].to_numpy())\n",
    "                segment_numbers.append(num_segments)\n",
    "                neuron_id += 1\n",
    "                X_class.append(sample_query[\"class\"].to_numpy())\n",
    "\n",
    "        # setup Y and X matrices\n",
    "        Y = np.concatenate(Y)\n",
    "        X_class = np.concatenate(X_class)\n",
    "        X = np.zeros((Y.shape[0], neuron_id+1))\n",
    "        # segment class covariate\n",
    "        X[X_class == class_2,0] = 1\n",
    "\n",
    "        cs = np.concatenate([[0],np.cumsum(segment_numbers)])\n",
    "        cumulative_index = 0\n",
    "\n",
    "        for neuron in range(1, neuron_id):\n",
    "            X[cs[neuron-1]:cs[neuron],neuron+1] = 1\n",
    "        X_null = X[:,1:]\n",
    "\n",
    "        # Below are the steps for the permutation procedure as described in Winkler et. al.\n",
    "        # Step 1\n",
    "        X_pinv = np.linalg.pinv(X)\n",
    "        beta_hat = X_pinv @ Y\n",
    "        T0 = beta_hat[0]\n",
    "\n",
    "        # Step 2\n",
    "        X_null_pinv = np.linalg.pinv(X_null)\n",
    "        beta_null_hat = X_null_pinv @ Y\n",
    "        resid_null = Y - X_null @ beta_null_hat\n",
    "\n",
    "        Tjs = np.zeros((n_perms+1))\n",
    "        for _iter in tqdm(range(n_perms)):\n",
    "            # Step 3\n",
    "            for neuron in range(1, neuron_id):\n",
    "                resid_null[cs[neuron-1]:cs[neuron]] = np.random.permutation(resid_null[cs[neuron-1]:cs[neuron]])\n",
    "            Yj = np.random.permutation(resid_null) + X_null @ beta_null_hat\n",
    "\n",
    "            # Step 4\n",
    "            beta_hatj = X_pinv @ Yj\n",
    "            Tjs[_iter] = beta_hatj[0]\n",
    "        Tjs[-1] = T0\n",
    "        \n",
    "        # Step 6\n",
    "        upper_pval = np.sum(Tjs>=T0)/len(Tjs)\n",
    "        lower_pval = np.sum(Tjs<=T0)/len(Tjs)\n",
    "        if  upper_pval < 0.05/6:\n",
    "            print(f\"{classes[class_2]} > {classes[class_1]} in {measure}\")\n",
    "            print(f\"p-val was: {upper_pval}\")\n",
    "        elif lower_pval < 0.05/6:\n",
    "            print(f\"{classes[class_2]} < {classes[class_1]} in {measure}\")\n",
    "            print(f\"p-val was: {lower_pval}\")\n",
    "        else:\n",
    "            print(f\"{classes[class_2]} ~= {classes[class_1]} in {measure}\")\n",
    "            print(f\"upper p-val was: {upper_pval}, lower was {lower_pval}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "c48f87b51193a18c36f6ec1b39da40df380a4c3fb2fa54b3e413dc2378ec9052"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}