{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from skimage.transform import downscale_local_mean\n",
    "import napari\n",
    "from skimage import io\n",
    "import random\n",
    "import h5py\n",
    "from skimage import measure\n",
    "from brainlit.preprocessing import removeSmallCCs\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import subprocess\n",
    "import tables\n",
    "from napari_animation import AnimationWidget\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from parse_ara import *\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import brainrender\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import skeletonize\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from rabies_somadetector_data import brain2paths, brain2centers\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = \"r1\"\n",
    "channel = \"3channel\"\n",
    "dir = brain2paths[brain][0]\n",
    "vol_fg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][1]\n",
    "vol_bg = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "dir = brain2paths[brain][2]\n",
    "vol_endo = CloudVolume(dir, parallel=1, mip=0, fill_missing=False)\n",
    "print(vol_fg.shape)\n",
    "\n",
    "soma_centers = brain2centers[brain][0][0]\n",
    "nonsoma_centers = brain2centers[brain][1][2]\n",
    "\n",
    "print(f\"{len(soma_centers)} soma centers\")\n",
    "print(f\"{len(nonsoma_centers)} nonsoma centers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name = \"test\"\n",
    "\n",
    "# type = \"pos\"\n",
    "# for i, center in enumerate(soma_centers):\n",
    "#     if i >= 30 and i < 40:\n",
    "#         pass\n",
    "#     else:\n",
    "#         continue\n",
    "#     image_fg = vol_fg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "#     image_fg = image_fg[:,:,:,0]\n",
    "#     image_bg = vol_bg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "#     image_bg = image_bg[:,:,:,0]\n",
    "#     image_endo = vol_endo[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "#     image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "#     image = np.squeeze(np.stack([image_fg, image_bg, image_endo], axis=0))\n",
    "        \n",
    "#     fname = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/{dset_name}/{int(center[0])}_{int(center[1])}_{int(center[2])}_{type}.h5\"\n",
    "#     with h5py.File(fname, \"w\") as f:\n",
    "#         dset = f.create_dataset(\"image_3channel\", data=image)\n",
    "\n",
    "type = \"neg\"\n",
    "for i, center in enumerate(nonsoma_centers):\n",
    "    if i >= 5:\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    image_fg = vol_fg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_fg = image_fg[:,:,:,0]\n",
    "    image_bg = vol_bg[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_bg = image_bg[:,:,:,0]\n",
    "    image_endo = vol_endo[center[0]-24:center[0]+25,center[1]-24:center[1]+25, center[2]-24:center[2]+25]\n",
    "    image_endo = image_endo[:,:,:,0]\n",
    "\n",
    "\n",
    "    image = np.squeeze(np.stack([image_fg, image_bg, image_endo], axis=0))\n",
    "        \n",
    "    fname = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/{dset_name}/{int(center[0])}_{int(center[1])}_{int(center[2])}_{type}.h5\"\n",
    "    with h5py.File(fname, \"w\") as f:\n",
    "        dset = f.create_dataset(\"image_3channel\", data=image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "files_dir = f\"/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/brain{brain}/{channel}/test/\"\n",
    "onlyfiles = [f for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#test_files = [f for f in onlyfiles if f[:4] == \"test\"]\n",
    "test_files = [f for f in onlyfiles if \"Probabilities\" in f] #\"probabilities\"\n",
    "print(test_files)\n",
    "\n",
    "size_thresh = 500\n",
    "\n",
    "for threshold in np.arange(0.05,1.0,0.05):\n",
    "    tot_pos = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for filename in tqdm(test_files, disable=True):\n",
    "        fname = files_dir + filename\n",
    "        f = h5py.File(fname, \"r\")\n",
    "        pred = f.get(\"exported_data\")\n",
    "        pred = pred[0,:,:,:]\n",
    "        mask = pred>threshold\n",
    "        labels = measure.label(mask)\n",
    "        props = measure.regionprops(labels)\n",
    "\n",
    "        if \"pos\" in filename: \n",
    "            first = True\n",
    "            tot_pos += 1\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    if first:\n",
    "                        true_pos += 1\n",
    "                        first = False\n",
    "                    else:\n",
    "                        false_pos += 1\n",
    "        elif \"neg\" in filename:\n",
    "            for prop in props:\n",
    "                if prop[\"area\"] > size_thresh:\n",
    "                    false_pos += 1\n",
    "\n",
    "    recall = true_pos/tot_pos\n",
    "    recalls.append(recall)\n",
    "    if true_pos + false_pos == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "    precisions.append(precision)\n",
    "    if precision == 0 and recall == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2*precision*recall/(precision+recall)\n",
    "    print(f\"threshold: {threshold}: precision: {precision}, recall: {recall}, f-score: {fscore} for {tot_pos} positive samples in {len(test_files)} images\")\n",
    "\n",
    "fscores = [2*precision*recall/(precision+recall) if (precision != 0 and recall != 0) else 0 for precision,recall in zip(precisions, recalls) ]\n",
    "idx = np.argmax(fscores)\n",
    "best_threshold = np.arange(0.05,1.0,0.05)[idx]\n",
    "plt.plot(recalls, precisions, c='b')\n",
    "plt.scatter(recalls[idx], precisions[idx], c='r', label=f\"Max f-score: {fscores[idx]:.2f} thresh:{best_threshold:.2f}\")\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(\"Soma Detector Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_thresh = 500\n",
    "\n",
    "for filename in tqdm(test_files, disable=True):\n",
    "    print(f\"*************File: {filename}*********\")\n",
    "    im_fname = files_dir + filename[:-17] + \".h5\"\n",
    "    fname = files_dir + filename\n",
    "    f = h5py.File(fname, \"r\")\n",
    "    pred = f.get(\"exported_data\")\n",
    "    pred = pred[0,:,:,:]\n",
    "    mask = pred>best_threshold\n",
    "    labels = measure.label(mask)\n",
    "    props = measure.regionprops(labels)\n",
    "\n",
    "    if \"pos\" in filename: \n",
    "        first = True\n",
    "        tot_pos += 1\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"area of detected object: {area}\")\n",
    "                if first:\n",
    "                    true_pos += 1\n",
    "                    first = False\n",
    "                else:\n",
    "                    print(f\"Soma false positive Area: {area}\")\n",
    "                    f = h5py.File(im_fname, \"r\")\n",
    "                    im = f.get(\"image_3channel\")\n",
    "                    viewer = napari.Viewer(ndisplay=3)\n",
    "                    viewer.add_image(im[0,:,:,:])\n",
    "                    viewer.add_image(im[1,:,:,:])\n",
    "                    viewer.add_image(im[2,:,:,:])\n",
    "                    viewer.add_labels(mask)\n",
    "                    viewer.add_labels(labels == prop[\"label\"], name=f\"soma false positive area: {area}\")\n",
    "                    false_pos += 1\n",
    "        if first == True:\n",
    "            print(f\"Soma false negative\")\n",
    "            f = h5py.File(im_fname, \"r\")\n",
    "            im = f.get(\"image_3channel\")\n",
    "            viewer = napari.Viewer(ndisplay=3)\n",
    "            viewer.add_image(im[0,:,:,:])\n",
    "            viewer.add_image(im[1,:,:,:])\n",
    "            viewer.add_image(im[2,:,:,:])\n",
    "            viewer.add_labels(mask, name=\"Soma false negative\")\n",
    "    elif \"neg\" in filename:\n",
    "        for prop in props:\n",
    "            area = prop[\"area\"]\n",
    "            if area > size_thresh:\n",
    "                print(f\"Nonsoma false positive Area: {area}\")\n",
    "                f = h5py.File(im_fname, \"r\")\n",
    "                im = f.get(\"image_3channel\")\n",
    "                viewer = napari.Viewer(ndisplay=3)\n",
    "                viewer.add_image(im[0,:,:,:])\n",
    "                viewer.add_image(im[1,:,:,:])\n",
    "                viewer.add_image(im[2,:,:,:])\n",
    "                viewer.add_labels(mask)\n",
    "                viewer.add_labels(labels == prop[\"label\"], name=f\"nonsoma false positive area: {area}\")\n",
    "                false_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make point layer - ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "point_path = \"precomputed://https://dlab-colm.neurodata.io/2021_10_06/8557/point_preds\"\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'segmentation',\n",
    "    data_type       = 'uint64', # Channel images might be 'uint8'\n",
    "    # raw, jpeg, compressed_segmentation, fpzip, kempressed, compresso\n",
    "    encoding        = 'raw', \n",
    "    resolution      = [4, 4, 40], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    mesh            = 'mesh',\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = [ 512, 512, 16 ], # units are voxels\n",
    "    volume_size     = [ 250000, 250000, 25000 ], # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(point_path, info=info)\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_somas = []\n",
    "for soma in somas:\n",
    "    if soma[2] <= 3000:\n",
    "        new_somas.append(soma)\n",
    "len(new_somas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_ra = np.array(new_somas)\n",
    "plt.hist(soma_ra[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer(ndisplay=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fg = vol_fg[:256,:256,:300, 0]\n",
    "im_bg = vol_bg[:256,:256,:300, 0]\n",
    "im_endo = vol_endo[:256,:256,:300, 0]\n",
    "\n",
    "image = np.squeeze(np.stack([im_fg, im_bg, im_endo], axis=0))\n",
    "fname = \"/Users/thomasathey/Desktop/im.h5\"\n",
    "\n",
    "with h5py.File(fname, \"w\") as f:\n",
    "    dset = f.create_dataset(\"image_3channel\", data=image)\n",
    "\n",
    "subprocess.run([\"/Applications/ilastik-1.3.3post3-OSX.app/Contents/ilastik-release/run_ilastik.sh\", \"--headless\", \"--project=/Users/thomasathey/Documents/mimlab/mouselight/ailey/soma_detection/matt_soma_rabies_pix_3ch.ilp\", fname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Labels</span><span style=\"color: #000000; text-decoration-color: #000000\"> layer </span><span style=\"color: #008000; text-decoration-color: #008000\">'Labels'</span><span style=\"color: #000000; text-decoration-color: #000000\"> at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x176218a30</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mLabels\u001b[0m\u001b[39m layer \u001b[0m\u001b[32m'Labels'\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x176218a30\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = h5py.File(\"/Users/thomasathey/Desktop/im_Probabilities.h5\", \"r\")\n",
    "pred = f.get(\"exported_data\")\n",
    "\n",
    "pred = pred[0,:,:,:]\n",
    "\n",
    "mask = pred > 0.55\n",
    "labels = measure.label(mask)\n",
    "props = measure.regionprops(labels)\n",
    "\n",
    "results = []\n",
    "for prop in props:\n",
    "    if prop[\"area\"] > 500:\n",
    "        location = list(np.add((0,0,0), prop[\"centroid\"]))\n",
    "        print(location)\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=3)\n",
    "viewer.add_image(np.squeeze(im_fg))\n",
    "viewer.add_labels(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "new_pts = []\n",
    "for point in a:\n",
    "    first = math.isclose(point[0],int(point[0]))\n",
    "    second = math.isclose(np.abs(point[1]-int(point[1])), 0.5)\n",
    "    third = math.isclose(np.abs(point[2]-int(point[2])), 0.5)\n",
    "    if first and second and third:\n",
    "        continue\n",
    "    else:\n",
    "        new_pts.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5dc00d68ff54f8375e99934614da4863299fb9e10af4294c095b7f517546ff26"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('docs_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
